{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial News Sentiment Analysis\n",
    "\n",
    "### Description\n",
    "\n",
    "This classification task is based on the Kaggle dataset: <a href=https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis >Financial Sentiment Analysis</a>. The dataset is under public domain license (v10.0).\n",
    "\n",
    "---\n",
    "### Table of contents\n",
    "\n",
    "1. [Dataset](#dataset)\n",
    "2. [Data preparation](#preparation)\n",
    "3. [Classification](#classification)\n",
    "   1. [Simple Conv](#)\n",
    "   2. [LSTM](#)\n",
    "   3. [GRU](#)\n",
    "   4. [Bidirectional](#)\n",
    "   5. [Conv1d](#)\n",
    "   6. [FinBERT](#finbert)\n",
    "4. [Model Comparison](#comparison)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score,recall_score,precision_score\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from keras import layers\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data//data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence Sentiment\n",
      "0     The GeoSolutions technology will leverage Bene...  positive\n",
      "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
      "2     For the last quarter of 2010 , Componenta 's n...  positive\n",
      "3     According to the Finnish-Russian Chamber of Co...   neutral\n",
      "4     The Swedish buyout firm has sold its remaining...   neutral\n",
      "...                                                 ...       ...\n",
      "5837  RISING costs have forced packaging producer Hu...  negative\n",
      "5838  Nordic Walking was first used as a summer trai...   neutral\n",
      "5839  According shipping company Viking Line , the E...   neutral\n",
      "5840  In the building and home improvement trade , s...   neutral\n",
      "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive\n",
      "\n",
      "[5842 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     3130\n",
      "positive    1852\n",
      "negative     860\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.bar(df[\"Sentiment\"].value_counts().index,df[\"Sentiment\"].value_counts().values)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Occurences of labels\")\n",
    "print(df[\"Sentiment\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is **imbalanced**: almost 2x positive label than negative and 2x neutral label than positive.\n",
    "\n",
    "**Solution**: use imblearn RandomOverSampler. (Under-sampling would make dataset insufficiently small)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Sentence\"]\n",
    "y = encoder.transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4673,) (1169,) (4673,) (1169,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = sampler.fit_resample(X_train.to_numpy().reshape(-1, 1), y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_over).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7440, 1) (7440,)\n"
     ]
    }
   ],
   "source": [
    "print(X_over.shape,y_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_words=round(sum([len(i.split()) for i in X_train])/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=10000,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=avg_words)\n",
    "text_vectorizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim=10000, \n",
    "                             output_dim=128, \n",
    "                             embeddings_initializer=\"uniform\", \n",
    "                             input_length=avg_words, \n",
    "                             name=\"embedding_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple Keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\") \n",
    "x = text_vectorizer(inputs) \n",
    "x = embedding(x) \n",
    "x = layers.GlobalAveragePooling1D()(x) \n",
    "outputs = layers.Dense(3, activation='softmax')(x) \n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") \n",
    "\n",
    "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 21)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 21, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d_4   (None, 128)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,387\n",
      "Trainable params: 1,280,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.9920 - accuracy: 0.5905\n",
      "Epoch 2/10\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.6640 - accuracy: 0.7960\n",
      "Epoch 3/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.4363 - accuracy: 0.8724\n",
      "Epoch 4/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.3186 - accuracy: 0.9090\n",
      "Epoch 5/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.2542 - accuracy: 0.9290\n",
      "Epoch 6/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.2145 - accuracy: 0.9364\n",
      "Epoch 7/10\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.1883 - accuracy: 0.9430\n",
      "Epoch 8/10\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.1698 - accuracy: 0.9477\n",
      "Epoch 9/10\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.1589 - accuracy: 0.9493\n",
      "Epoch 10/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.1493 - accuracy: 0.9497\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(X_over, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              y_over,\n",
    "                              epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x258ca16b3d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_1_history.history[\"accuracy\"],label=\"Accuracy\")\n",
    "plt.plot(model_1_history.history[\"loss\"],label=\"Loss\")\n",
    "plt.title(\"Accuracy vs. Loss over epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn_vector = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn = []\n",
    "for pred in y_pred_cnn_vector:\n",
    "    if max(pred) ==pred[0]:\n",
    "        y_pred_cnn.append(0)\n",
    "    elif max(pred) ==pred[1]:\n",
    "        y_pred_cnn.append(1)\n",
    "    else:\n",
    "        y_pred_cnn.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_hat,y_true,model_name=\"model\"):\n",
    "    return {\n",
    "        \"model\":model_name,\n",
    "        \"f1\":f1_score(y_hat,y_true,average=\"weighted\"),\n",
    "        \"accuracy\":accuracy_score(y_hat,y_true),\n",
    "        \"recall\": recall_score(y_hat,y_true,average=\"weighted\"),\n",
    "        \"precision\":precision_score(y_hat,y_true,average=\"weighted\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'conv1d', 'f1': 0.6561582122846894, 'accuracy': 0.6586826347305389, 'recall': 0.6586826347305389, 'precision': 0.656805945263283}\n"
     ]
    }
   ],
   "source": [
    "print(get_scores(y_pred_cnn,y_test,\"conv1d\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(input_dim=10000,\n",
    "                                   output_dim=128,\n",
    "                                   embeddings_initializer=\"uniform\",\n",
    "                                   input_length=avg_words,\n",
    "                                   name=\"embedding1\")\n",
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "\n",
    "x = text_vectorizer(inputs)\n",
    "x= embedding_layer(x)\n",
    "x = layers.LSTM(units=64)(x)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "lstm_model = tf.keras.Model(inputs,outputs,name=\"lstm_model\")\n",
    "\n",
    "lstm_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=tf.keras.optimizers.Adam(),\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 21)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding1 (Embedding)      (None, 21, 128)           1280000   \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,603\n",
      "Trainable params: 1,329,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "233/233 [==============================] - 7s 22ms/step - loss: 0.7782 - accuracy: 0.6384\n",
      "Epoch 2/10\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.3188 - accuracy: 0.8863\n",
      "Epoch 3/10\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.2145 - accuracy: 0.9281\n",
      "Epoch 4/10\n",
      "233/233 [==============================] - 6s 27ms/step - loss: 0.1733 - accuracy: 0.9394\n",
      "Epoch 5/10\n",
      "233/233 [==============================] - 5s 22ms/step - loss: 0.1594 - accuracy: 0.9450\n",
      "Epoch 6/10\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.1461 - accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "233/233 [==============================] - 5s 22ms/step - loss: 0.1412 - accuracy: 0.9484\n",
      "Epoch 8/10\n",
      "233/233 [==============================] - 5s 21ms/step - loss: 0.1250 - accuracy: 0.9507\n",
      "Epoch 9/10\n",
      "233/233 [==============================] - 5s 23ms/step - loss: 0.1217 - accuracy: 0.9520\n",
      "Epoch 10/10\n",
      "233/233 [==============================] - 7s 32ms/step - loss: 0.1213 - accuracy: 0.9522\n"
     ]
    }
   ],
   "source": [
    "lstm_history = lstm_model.fit(X_over,y_over,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 6ms/step - loss: 1.8381 - accuracy: 0.6193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.83811616897583, 0.6193327903747559]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer3 = layers.Embedding(input_dim=10000,\n",
    "                                          output_dim =128,\n",
    "                                          embeddings_initializer = \"uniform\",\n",
    "                                          input_length=avg_words,\n",
    "                                          name=\"embedding3\")\n",
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding_layer3(x)\n",
    "x = layers.GRU(64)(x)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "gru_model = tf.keras.Model(inputs,outputs,name=\"gru_model\")\n",
    "\n",
    "gru_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer = tf.keras.optimizers.Adam(),\n",
    "                  metrics=[\"accuracy\"]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "233/233 [==============================] - 5s 23ms/step - loss: 0.4478 - accuracy: 0.8325\n",
      "Epoch 2/10\n",
      "233/233 [==============================] - 6s 25ms/step - loss: 0.2134 - accuracy: 0.9238\n",
      "Epoch 3/10\n",
      "233/233 [==============================] - 6s 25ms/step - loss: 0.1672 - accuracy: 0.9391\n",
      "Epoch 4/10\n",
      "233/233 [==============================] - 7s 30ms/step - loss: 0.1560 - accuracy: 0.9437\n",
      "Epoch 5/10\n",
      "233/233 [==============================] - 6s 25ms/step - loss: 0.1449 - accuracy: 0.9470\n",
      "Epoch 6/10\n",
      "233/233 [==============================] - 5s 23ms/step - loss: 0.1338 - accuracy: 0.9511\n",
      "Epoch 7/10\n",
      "233/233 [==============================] - 6s 24ms/step - loss: 0.1316 - accuracy: 0.9508\n",
      "Epoch 8/10\n",
      "233/233 [==============================] - 6s 24ms/step - loss: 0.1268 - accuracy: 0.9515\n",
      "Epoch 9/10\n",
      "233/233 [==============================] - 5s 22ms/step - loss: 0.1259 - accuracy: 0.9515\n",
      "Epoch 10/10\n",
      "233/233 [==============================] - 6s 24ms/step - loss: 0.1191 - accuracy: 0.9540\n"
     ]
    }
   ],
   "source": [
    "gru_history  = gru_model.fit(X_over,y_over,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 8ms/step - loss: 1.9854 - accuracy: 0.6441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9854001998901367, 0.6441403031349182]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer4 = layers.Embedding(input_dim=10000,\n",
    "                                    output_dim=128,\n",
    "                                    embeddings_initializer=\"uniform\",\n",
    "                                    input_length=avg_words,\n",
    "                                    name=\"embedding4\")\n",
    "\n",
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding_layer4(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64,))(x)\n",
    "outputs = layers.Dense(3,activation=\"softmax\")(x)\n",
    "\n",
    "bdir_model = tf.keras.Model(inputs,outputs,name=\"bdir_model\")\n",
    "bdir_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer = tf.keras.optimizers.Adam(),\n",
    "                   metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "233/233 [==============================] - 8s 34ms/step - loss: 0.6604 - accuracy: 0.7179\n",
      "Epoch 2/10\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.2623 - accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "233/233 [==============================] - 7s 29ms/step - loss: 0.1751 - accuracy: 0.9387\n",
      "Epoch 4/10\n",
      "233/233 [==============================] - 7s 28ms/step - loss: 0.1472 - accuracy: 0.9456\n",
      "Epoch 5/10\n",
      "233/233 [==============================] - 9s 40ms/step - loss: 0.1408 - accuracy: 0.9473\n",
      "Epoch 6/10\n",
      "233/233 [==============================] - 8s 36ms/step - loss: 0.1326 - accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "233/233 [==============================] - 7s 29ms/step - loss: 0.1371 - accuracy: 0.9476\n",
      "Epoch 8/10\n",
      "233/233 [==============================] - 7s 31ms/step - loss: 0.1212 - accuracy: 0.9527\n",
      "Epoch 9/10\n",
      "233/233 [==============================] - 7s 29ms/step - loss: 0.1163 - accuracy: 0.9543\n",
      "Epoch 10/10\n",
      "233/233 [==============================] - 7s 28ms/step - loss: 0.1193 - accuracy: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258bb2d2fd0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdir_history = bdir_model.fit(X_over,y_over,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 8ms/step - loss: 1.9405 - accuracy: 0.6151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.940460205078125, 0.6150556206703186]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdir_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer5 = layers.Embedding(input_dim=10000,\n",
    "                                    output_dim=128,\n",
    "                                    embeddings_initializer=\"uniform\",\n",
    "                                    input_length=avg_words,\n",
    "                                    name=\"embedding5\")\n",
    "\n",
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding_layer5(x)\n",
    "\n",
    "x = layers.Conv1D(filters=32,kernel_size=5,activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(3,activation=\"softmax\")(x)\n",
    "\n",
    "conv1d_model = tf.keras.Model(inputs,outputs,name=\"conv1d_model\")\n",
    "conv1d_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer = tf.keras.optimizers.Adam(),\n",
    "                   metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "233/233 [==============================] - 3s 11ms/step - loss: 0.4134 - accuracy: 0.8620\n",
      "Epoch 2/10\n",
      "233/233 [==============================] - 4s 16ms/step - loss: 0.2160 - accuracy: 0.9254\n",
      "Epoch 3/10\n",
      "233/233 [==============================] - 3s 14ms/step - loss: 0.1664 - accuracy: 0.9390\n",
      "Epoch 4/10\n",
      "233/233 [==============================] - 3s 12ms/step - loss: 0.1520 - accuracy: 0.9427\n",
      "Epoch 5/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 0.1435 - accuracy: 0.9445\n",
      "Epoch 6/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 0.1389 - accuracy: 0.9456\n",
      "Epoch 7/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.1352 - accuracy: 0.9476\n",
      "Epoch 8/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.1338 - accuracy: 0.9487\n",
      "Epoch 9/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.1311 - accuracy: 0.9497\n",
      "Epoch 10/10\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.1302 - accuracy: 0.9491\n"
     ]
    }
   ],
   "source": [
    "conv1d_history = conv1d_model.fit(X_over,y_over,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 1.3225 - accuracy: 0.6450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3224947452545166, 0.6449957489967346]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FinBERT (hugging-face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Peer Peugeot fell 0.81 pct as its sales rose only 6.3 pct from the same period last year .'\n",
      " 'The proposal that the Board of Directors will make at the Annual General Meeting is attached as a whole to this release .'\n",
      " 'Tesla is recalling 2,700 Model X cars: https://t.co/8Z7BkVsTl9 $TSLA'\n",
      " ... '$FB trending nicely, intraday.'\n",
      " '$IBIO  up 10% in premarket ready for lift off'\n",
      " '$NFLX VISION : short term consolidation then movement higher http://stks.co/j05uu']\n"
     ]
    }
   ],
   "source": [
    "print(X_over.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "results = nlp(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'negative', 'score': 0.6489782333374023}, {'label': 'negative', 'score': 0.6363905668258667}, {'label': 'negative', 'score': 0.4519396424293518}, {'label': 'negative', 'score': 0.6896196007728577}, {'label': 'negative', 'score': 0.6830145120620728}, {'label': 'negative', 'score': 0.6694044470787048}, {'label': 'neutral', 'score': 0.5045798420906067}, {'label': 'negative', 'score': 0.7276839017868042}, {'label': 'neutral', 'score': 0.5006902813911438}, {'label': 'positive', 'score': 0.467952162027359}]\n"
     ]
    }
   ],
   "source": [
    "print(results[:10])\n",
    "# pos:2\n",
    "# neg:0\n",
    "# neu:1\n",
    "y_pred_finbert =[]\n",
    "for result in results:\n",
    "    if result[\"label\"] ==\"negative\":\n",
    "        y_pred_finbert.append(0)\n",
    "    elif result[\"label\"] ==\"neutral\":\n",
    "        y_pred_finbert.append(1)\n",
    "    else:\n",
    "        y_pred_finbert.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_acc = get_scores(y_pred_finbert,y_test,\"finBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'finBERT', 'f1': 0.12174375922450009, 'accuracy': 0.16766467065868262, 'recall': 0.16766467065868262, 'precision': 0.14849657444630288}\n"
     ]
    }
   ],
   "source": [
    "print(finbert_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,484,547\n",
      "Trainable params: 109,484,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18916\\449558197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"string\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ProsusAI/finbert\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtext_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_over\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_layer5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   2289\u001b[0m                 method).\n\u001b[0;32m   2290\u001b[0m         \"\"\"\n\u001b[1;32m-> 2291\u001b[1;33m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[0;32m   2292\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2293\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2697\u001b[0m         )\n\u001b[0;32m   2698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2699\u001b[1;33m         return self._encode_plus(\n\u001b[0m\u001b[0;32m   2700\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2701\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[0mbatched_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         batched_output = self._batch_encode_plus(\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[0mbatched_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[0mis_split_into_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    427\u001b[0m         )\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[0;32m    430\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "embedding_layer6 = layers.Embedding(input_dim=10000,\n",
    "                                    output_dim=128,\n",
    "                                    embeddings_initializer=\"uniform\",\n",
    "                                    input_length=avg_words,\n",
    "                                    name=\"embedding6\")\n",
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "  \n",
    "\n",
    "x = embedding_layer5(x)\n",
    "x = model(x)\n",
    "outputs = layers.Dense(3,activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,482,240\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        \n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1520, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        filtered_tb = _process_traceback_frames(e.__traceback__)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filenq6n8y6m.py\", line 36, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_file5cdmw9pt.py\", line 30, in tf__call\n        outputs = ag__.converted_call(ag__.ld(self).bert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), token_type_ids=ag__.ld(token_type_ids), position_ids=ag__.ld(position_ids), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), encoder_hidden_states=ag__.ld(encoder_hidden_states), encoder_attention_mask=ag__.ld(encoder_attention_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filenq6n8y6m.py\", line 36, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_file743g5vag.py\", line 126, in tf__call\n        embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 45, in tf__call\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 39, in if_body_1\n        ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(input_ids), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(self).vocab_size,), dict(dtype=ag__.ld(input_ids).dtype), fscope)), dict(message=f\"input_ids must be smaller than the embedding layer's input dimension (got {ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(input_ids),), None, fscope)} >= {ag__.ld(self).vocab_size})\"), fscope)\n\n    TypeError: Exception encountered when calling layer \"tf_bert_model\" (type TFBertModel).\n    \n    in user code:\n    \n        File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1090, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1118, in call  *\n            outputs = self.bert(\n        File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            filtered_tb = _process_traceback_frames(e.__traceback__)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filenq6n8y6m.py\", line 36, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_file743g5vag.py\", line 126, in tf__call\n            embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 45, in tf__call\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 39, in if_body_1\n            ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(input_ids), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(self).vocab_size,), dict(dtype=ag__.ld(input_ids).dtype), fscope)), dict(message=f\"input_ids must be smaller than the embedding layer's input dimension (got {ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(input_ids),), None, fscope)} >= {ag__.ld(self).vocab_size})\"), fscope)\n    \n        TypeError: Exception encountered when calling layer \"bert\" (type TFBertMainLayer).\n        \n        in user code:\n        \n            File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1090, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 791, in call  *\n                embedding_output = self.embeddings(\n            File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                filtered_tb = _process_traceback_frames(e.__traceback__)\n            File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 45, in tf__call\n                ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n            File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 39, in if_body_1\n                ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(input_ids), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(self).vocab_size,), dict(dtype=ag__.ld(input_ids).dtype), fscope)), dict(message=f\"input_ids must be smaller than the embedding layer's input dimension (got {ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(input_ids),), None, fscope)} >= {ag__.ld(self).vocab_size})\"), fscope)\n        \n            TypeError: Exception encountered when calling layer \"embeddings\" (type TFBertEmbeddings).\n            \n            in user code:\n            \n                File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 205, in call  *\n                    tf.debugging.assert_less(\n            \n                TypeError: Value passed to parameter 'input' has DataType string not in list of allowed values: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, float16, uint32, uint64, qint8, quint8, qint32, qint16, quint16\n            \n            \n            Call arguments received by layer \"embeddings\" (type TFBertEmbeddings):\n              • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n              • position_ids=None\n              • token_type_ids=tf.Tensor(shape=(None, 1), dtype=int32)\n              • inputs_embeds=None\n              • past_key_values_length=0\n              • training=True\n        \n        \n        Call arguments received by layer \"bert\" (type TFBertMainLayer):\n          • self=tf.Tensor(shape=(None, 1), dtype=string)\n          • input_ids=None\n          • attention_mask=None\n          • token_type_ids=None\n          • position_ids=None\n          • head_mask=None\n          • inputs_embeds=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • past_key_values=None\n          • use_cache=True\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer \"tf_bert_model\" (type TFBertModel):\n      • self=tf.Tensor(shape=(None, 1), dtype=string)\n      • input_ids=None\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • encoder_hidden_states=None\n      • encoder_attention_mask=None\n      • past_key_values=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18916\\1691143598.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_over\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1520\u001b[1;33m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_using_dummy_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization_losses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36mtf__run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\u001b[0m in \u001b[0;36mtf__run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    124\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'token_type_ids'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[0membedding_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m                 \u001b[0mattention_mask_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mmask_seq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, past_key_values_length, training)\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'inputs_embeds'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mif_body_1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[1;32mdef\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_less\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"input_ids must be smaller than the embedding layer's input dimension (got {ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(input_ids),), None, fscope)} >= {ag__.ld(self).vocab_size})\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                     \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        \n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1520, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        filtered_tb = _process_traceback_frames(e.__traceback__)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filenq6n8y6m.py\", line 36, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_file5cdmw9pt.py\", line 30, in tf__call\n        outputs = ag__.converted_call(ag__.ld(self).bert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), token_type_ids=ag__.ld(token_type_ids), position_ids=ag__.ld(position_ids), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), encoder_hidden_states=ag__.ld(encoder_hidden_states), encoder_attention_mask=ag__.ld(encoder_attention_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filenq6n8y6m.py\", line 36, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_file743g5vag.py\", line 126, in tf__call\n        embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 45, in tf__call\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n    File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 39, in if_body_1\n        ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(input_ids), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(self).vocab_size,), dict(dtype=ag__.ld(input_ids).dtype), fscope)), dict(message=f\"input_ids must be smaller than the embedding layer's input dimension (got {ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(input_ids),), None, fscope)} >= {ag__.ld(self).vocab_size})\"), fscope)\n\n    TypeError: Exception encountered when calling layer \"tf_bert_model\" (type TFBertModel).\n    \n    in user code:\n    \n        File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1090, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1118, in call  *\n            outputs = self.bert(\n        File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            filtered_tb = _process_traceback_frames(e.__traceback__)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filenq6n8y6m.py\", line 36, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_file743g5vag.py\", line 126, in tf__call\n            embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 45, in tf__call\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n        File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 39, in if_body_1\n            ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(input_ids), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(self).vocab_size,), dict(dtype=ag__.ld(input_ids).dtype), fscope)), dict(message=f\"input_ids must be smaller than the embedding layer's input dimension (got {ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(input_ids),), None, fscope)} >= {ag__.ld(self).vocab_size})\"), fscope)\n    \n        TypeError: Exception encountered when calling layer \"bert\" (type TFBertMainLayer).\n        \n        in user code:\n        \n            File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1090, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 791, in call  *\n                embedding_output = self.embeddings(\n            File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                filtered_tb = _process_traceback_frames(e.__traceback__)\n            File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 45, in tf__call\n                ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n            File \"C:\\Users\\nemet\\AppData\\Local\\Temp\\__autograph_generated_filewanf6ylm.py\", line 39, in if_body_1\n                ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(input_ids), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(self).vocab_size,), dict(dtype=ag__.ld(input_ids).dtype), fscope)), dict(message=f\"input_ids must be smaller than the embedding layer's input dimension (got {ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(input_ids),), None, fscope)} >= {ag__.ld(self).vocab_size})\"), fscope)\n        \n            TypeError: Exception encountered when calling layer \"embeddings\" (type TFBertEmbeddings).\n            \n            in user code:\n            \n                File \"c:\\Users\\nemet\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 205, in call  *\n                    tf.debugging.assert_less(\n            \n                TypeError: Value passed to parameter 'input' has DataType string not in list of allowed values: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, float16, uint32, uint64, qint8, quint8, qint32, qint16, quint16\n            \n            \n            Call arguments received by layer \"embeddings\" (type TFBertEmbeddings):\n              • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n              • position_ids=None\n              • token_type_ids=tf.Tensor(shape=(None, 1), dtype=int32)\n              • inputs_embeds=None\n              • past_key_values_length=0\n              • training=True\n        \n        \n        Call arguments received by layer \"bert\" (type TFBertMainLayer):\n          • self=tf.Tensor(shape=(None, 1), dtype=string)\n          • input_ids=None\n          • attention_mask=None\n          • token_type_ids=None\n          • position_ids=None\n          • head_mask=None\n          • inputs_embeds=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • past_key_values=None\n          • use_cache=True\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer \"tf_bert_model\" (type TFBertModel):\n      • self=tf.Tensor(shape=(None, 1), dtype=string)\n      • input_ids=None\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • encoder_hidden_states=None\n      • encoder_attention_mask=None\n      • past_key_values=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_over,y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "605e616c404bc2856ab367308b2bb812f81f8f4d1e902ec953b7bc9f683a5d50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
